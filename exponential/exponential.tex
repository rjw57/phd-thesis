\begin{savequote}
Better to bend than to break.
\qauthor{Scottish Proverb}
\end{savequote}

\chapter{Rotors as Exponentiated Bivectors}

Referring to the displacement rotors presented above, we
see that all of them have a common form; they are all exponentiated bivectors.
Rotations are generated by bivectors with no component parallel to
$n$ and translations by a bivector with no components perpendicular to $n$. We
may thus postulate that all displacement rotors\footnote{There also exist dilation rotors but 
these will not be discussed in this paper.} can be expressed as
\[
R = \exp(B)
\]
where $B$ is the sum of two bivectors, one formed from two vectors which have no
components parallel to $e$ or $\bar{e}$. The other is formed from the outer product 
of vectors with no components parallel to $e$ or $\bar{e}$ and $n$. The effect of this
is to separate the basis bivectors of $B$ into one with components of the form $e_i \wedge e_j$
and one with components of the form $e_i \wedge e$ and $e_i \wedge \bar{e}$.

We shall proceed assuming that all displacement rotors can be written as
the exponentiation of a bivector of the form $B = ab + cn$ where $a$, $b$ and
$c$ are independent of $n$, i.e. if $n \in \mathcal{A}(m+1,1)$ then $\{a,b,c\} \in \mathbb{R}^m$.
It is clear that the set of all $B$ is some
linear sub-space of all the bivectors.

We now suppose that we may interpolate rotors by defining
some function $\ell(R)$ which acts upon rotors to give the generating
bivector element. We then perform direct interpolation of these generators. We postulate that
direct interpolation of these bivectors, as in the reformulation of quaternionic interpolation
above, will give some smooth interpolation between the displacements.
It is therefore a defining property of $\ell(R)$ that
\begin{equation}
R \equiv \exp(\ell(R))
\end{equation}
and so $\ell(R)$ may be considered as to act as a logarithm-like function in this context.
It is worth noting that $\ell(R)$ does not possess all the properties usually associated with logarithms, notably that, since $\exp(A)\exp(B)$ is not generally equal to $\exp(B)\exp(A)$ in non-commuting algebras,
$\ell(\exp(A)\exp(B))$ cannot be equal to $A + B$ except in special cases.

To avoid the the risk of assigning more properties to $\ell(R)$ than we have shown, we shall
resist the temptation to denote the function $\log(R)$. The most obvious property of $\log(\cdot)$ that
$\ell(\cdot)$ doesn't possess is $\log(AB) = \log(A) + \log(B)$. This is clear since the geometric product
is not commutative in general whereas addition is.

\section{Form of $\exp(B)$ in Euclidean space}
\label{subsec:form}

\begin{lemma}
\label{lem:bk}
If $B$ is of the form $B=\phi P+tn$ where 
$t \in \mathbb{R}^n$, $\phi$ is some scalar and $P$ is a 2-blade 
where $P^2 = -1$ then, for any $k \in \mathbb{Z}^+$, 
\[
B^{k}=\phi^k P^{k}+\alpha _{k}^{(1)}\phi Ptn+
\alpha _{k}^{(2)}\phi^2 PtnP+\alpha _{k}^{(3)}\phi tnP+\alpha _{k}^{(4)}tn
\]
with the following recurrence relations for $\alpha _{k}^{(\cdot )}$,
$k>0$ 

\begin{centering}

\begin{tabular}{r@{$\ =\ $}lr@{$\ =\ $}l}
$\alpha _{k}^{(1)}$ & $- \phi^2 \alpha _{k-1}^{(2)}$ &
$\alpha _{k}^{(2)}$ & $\alpha _{k-1}^{(1)}$\\
$\alpha _{k}^{(3)}$ & $\alpha _{k-1}^{(4)}$ &
$\alpha _{k}^{(4)}$ & $\phi^{k-1}P^{k-1} - \phi^2 \alpha_{k-1}^{(3)}$
\end{tabular}

\end{centering}

\noindent with 
$\alpha _{0}^{(1)}=\alpha _{0}^{(2)}=
\alpha _{0}^{(3)}=\alpha _{0}^{(4)}=0$.
\end{lemma}
\begin{proof}
Firstly note that the thm is trivially provable by direct 
substitution for the cases $k=0$ and $k=1$. We thereafter seek a 
proof by induction.

Assuming the expression for $B^{k-1}$ is correct, we post-multiply
by $\phi P+tn$ to obtain
\begin{eqnarray*}
B^k & = & \phi^k P^k + \alpha_{k-1}^{(1)}\phi^2 PtnP + 
          \alpha_{k-1}^{(2)}\phi^3 PtnP^2 + \alpha_{k-1}^{(3)}\phi^2 tnP^2 + \\
    &   & \alpha_{k-1}^{(4)}\phi tnP + \phi^{k-1} P^{k-1} tn + \alpha_{k-1}^{(1)}\phi P(tn)^2 +
          \alpha_{k-1}^{(2)}\phi^2 PtnPtn + \\
    &   & \alpha_{k-1}^{(3)}\phi tnPtn +
	  \alpha_{k-1}^{(4)}(tn)^2
\end{eqnarray*}

Substituting $P^2 = -1$, $(tn)^2 = - tn^2t = 0$ and noting that
$nPt = - Ptn$ leading to $tnPtn = - tPtn^2 = 0$

\begin{eqnarray*}
B^k & = & \phi^k P^k + \alpha_{k-1}^{(1)}\phi^2 PtnP -
          \alpha_{k-1}^{(2)}\phi^3 Ptn - \alpha_{k-1}^{(3)}\phi^2 tn + \\
    &   & \alpha_{k-1}^{(4)}\phi tnP + \phi^{k-1} P^{k-1} tn \\
    & = & \phi^k P^k - (\alpha_{k-1}^{(2)}\phi^2)\phi Ptn +
          \alpha_{k-1}^{(1)}\phi^2 PtnP + \\
    &   & \alpha_{k-1}^{(4)}\phi tnP +
	  (\phi^{k-1} P^{k-1}  - \alpha_{k-1}^{(3)}\phi^2) tn
\end{eqnarray*}

Equating like coefficients we obtain the required recurrence relations.
\end{proof}

\begin{lemma}
\label{lem:bkexp}
Assuming the form of $B$ given in lemma \ref{lem:bk}, for 
$k\in \mathbb{Z}^{+}$,\[
B^{2k}=(-1)^k\phi^{2k}-k(-1)^k\phi^{2k-1}[tnP + Ptn]
\]and\[
B^{2k+1}=(-1)^k\phi^{2k+1}P + k \phi^{2k} (-1)^k [ tn - PtnP ] + (-1)^k\phi^{2k} tn
\]
\end{lemma}
\begin{proof}
Starting from $\alpha _{0}^{(.)}=0$ it is clear that the recurrence
relations above imply that $\alpha _{k}^{(1)}=\alpha _{k}^{(2)}=0\; \forall \: k \ge 0$.
Substituting $\alpha _{k}^{(3)}=\alpha _{k-1}^{(4)}$ it is trivial to show
that the relation for $\alpha _{k}^{(4)}$ is satisfied by \[
\alpha _{k}^{(4)}=\begin{cases}
 \frac{k}{2}(\phi P)^{k-1} & k\textrm{ even,}\\
 \frac{k+1}{2}(\phi P)^{k-1} & k\textrm{ odd.}\end{cases}\]
When substituted into the expression for $B^{k}$, we obtain the
result stated above.
\end{proof}

\begin{thm}
\label{lem:exp}
If $B$ is a bivector of the form given in thm \ref{lem:bk}
then, defining 
$t_\parallel$ as the component of $t$ lying in the plane of $P$ 
and $t_\perp = t - t_\parallel$,
\[
\exp(B) = \left[ \cos(\phi) + \sin(\phi) P \right] \left[ 1 + t_\perp n \right] + \sinc(\phi) t_\parallel n
\]
\end{thm}
\begin{proof}
Consider the power series expansion of $\exp (B)$,
\[
\exp (B)=\sum _{k=0}^{\infty }\frac{B^{k}}{k!}=\sum _{k=0}^{\infty }\left[\frac{B^{2k}}{(2k)!}+\frac{B^{2k+1}}{(2k+1)!}\right]\]
Substituting the expansion for $B^{2k}$ and $B^{2k+1}$ from 
lemma \ref{lem:bkexp}
\begin{align*}
\exp (B)= & \sum _{k=0}^{\infty }\left[
 \frac{
   (-1)^k\phi^{2k}
 }{(2k)!} - k \frac{
   (-1)^k\phi^{2k-1}
 }{(2k)!} \left(tnP + Ptn\right)
\right]\\
+ & \sum _{k=0}^{\infty }\left[
 \frac{
   (-1)^k\phi^{2k}
 }{(2k+1)!} \left(\phi P + tn\right) + 
 k\frac{
   (-1)^k \phi^{2k}
 }{(2k+1)!} \left( tn - PtnP \right)\right]
\end{align*}
We now substitute the following power-series representations

\begin{centering}

%\[
%\begin{array}{r@{=}l@{\quad}r@{=}l}
%\cos(z) & \sum_{k=0}^\infty \frac{(-1)^k z^{2k}}{(2k)!} &
%\sinc(z) & \sum_{k=0}^\infty \frac{(-1)^k z^{2k}}{(2k+1)!} \\
%- z \sin(z) & \sum_{k=0}^\infty 2k \frac{(-1)^k z^{2k}}{(2k)!} &
%\cos(z) - \sinc(z) & \sum_{k=0}^\infty 2k \frac{(-1)^k z^{2k}}{(2k+1)!}
%\end{array}
%\]

\begin{tabular}{r@{$\ =\ $}l@{$\quad$}r@{$\ = \ $}l}
\multicolumn{4}{l}{\vspace{0.1cm}} \\
$\cos(z)$ & $\sum_{k=0}^\infty \frac{(-1)^k z^{2k}}{(2k)!}$ &
$\sinc(z)$ & $\sum_{k=0}^\infty \frac{(-1)^k z^{2k}}{(2k+1)!}$ \\
\multicolumn{4}{l}{\vspace{0.1cm}} \\
$- z \sin(z)$ & $\sum_{k=0}^\infty 2k \frac{(-1)^k z^{2k}}{(2k)!}$ &
$\cos(z) - \sinc(z)$ & $\sum_{k=0}^\infty 2k \frac{(-1)^k z^{2k}}{(2k+1)!}$ \\
\multicolumn{4}{l}{\vspace{0.1cm}} \\
\end{tabular}

\end{centering}

\noindent to obtain
\begin{align*}
\exp(B) = & 
  \cos \phi + \sin(\phi) \frac{1}{2} (tnP + Ptn) + \sinc(\phi) (\phi P + tn) \\
+ & \frac{1}{2} \left[ \cos(\phi) - \sinc(\phi) \right] (tn - PtnP)
\end{align*}
By considering parallel and perpendicular components of $t$ with
respect to the plane of $P$ is easy to verify that
$tnP + Ptn = 2 Pt_\perp n$ and $PtnP = (t_\parallel - t_\perp)n$ hence
\begin{align*}
\exp(B) = & 
  \cos \phi + \sin(\phi) P t_\perp n + \sinc(\phi) (\phi P + tn) + \left[ \cos(\phi) - \sinc(\phi) \right] t_\perp n \\
  = & \cos (\phi) \left[ 1 + t_\perp n \right] +
  \sin(\phi) P \left[ 1 + t_\perp n \right] + \sinc(\phi) t_\parallel n \\
  = & \left[ \cos(\phi) + \sin(\phi) P \right] \left[ 1 + t_\perp n \right] + \sinc(\phi) t_\parallel n 
\end{align*}
as required.
\end{proof}

\begin{definition}
A \emph{twist} is a rotor whose action is to rotate by $\phi$ in the 
plane of $P$ whilst translating along a vector $a$ perpendicular to
the plane of $P$. It may therefore be 
defined by the rotor 
\[
\tau(\phi, P, a) =
 \left[ \cos\left(\frac{\phi}{2}\right) +
   \sin\left(\frac{\phi}{2}\right)P
 \right]
 \left[
   1 + \frac{na}{2}
 \right]
\]
where $\phi$ is a scalar, $P$ is a $2$-blade normalised such that 
$P^2 = -1$ and $a$ is some vector satisfying $a \cdot n = a \cdot P = 0$.
\end{definition}

\begin{lemma}
The exponentiation function may be re-expressed using a twist
\[
\exp\left(\frac{\phi}{2}P + \frac{tn}{2}\right) =
\left[ 1 + \sinc\left(\frac{\phi}{2}\right)\frac{t_\parallel n}{2} \tilde{\tau}(\phi, P, - t_\perp) \right]
\tau(\phi, P, - t_\perp)
\]
\end{lemma}
\begin{proof}
We firstly substitute our definition of a twist into our form for the exponential
\begin{equation}
\exp\left(\frac{\phi}{2}P + \frac{tn}{2}\right) =
\tau(\phi, P, - t_\perp) + \sinc\left(\frac{\phi}{2}\right)\frac{t_\parallel n}{2}
\label{eqn:twistform}
\end{equation}
noting that, since twists are rotors, $\tau( \cdot ) \tilde{\tau}(\cdot) = 1$, it is
trivial to verify that the required expression is equivalent to this form of the exponential.
\end{proof}

\begin{lemma}
The expression
\[
 1 + \sinc\left(\frac{\phi}{2}\right)\frac{t_\parallel n}{2} \tilde{\tau}(\phi, P, - t_\perp)
\]
is a rotor which acts to translate along a vector $t'_\parallel$ given by
\[
t'_\parallel = - \sinc\left(\frac{\phi}{2}\right)
t_\parallel
\left(
\cos\left(\frac{\phi}{2}\right) -
\sin\left(\frac{\phi}{2}\right) P 
\right)
\]
\end{lemma}
\begin{proof}
The expression above may be obtained by substituting for the twist in the initial expression and simplifying. 
It is clearly a vector since multiplying $t_\parallel$ on the left by $P$ is just a rotation by $\pi / 2$ in the plane
of $P$.
\end{proof}

We have now developed the required thms and tools to discuss the
action of the rotor
\[
R = \exp\left(
\frac{\phi}{2} P + \frac{tn}{2}
\right)
\]
It translates along a vector $t_\perp$ which is the component of $t$ which does not lie in the
plane of $P$, rotates by $\phi$ in the plane of $P$ and finally translates along 
$t'_\parallel$ which is given by
\[
t'_\parallel =- \sinc\left(\frac{\phi}{2}\right)
t_\parallel
\left(
\cos\left(\frac{\phi}{2}\right) -
\sin\left(\frac{\phi}{2}\right) P 
\right)
\]
which is the component of $t$ lying in the
plane of $P$, rotated by $\phi/2$ in that plane.

\section{Checking $\exp(B)$ is a rotor}

It is sufficient to check that $\exp(B)$ satisfies the following
properties of a rotor $R$. % in Euclidean space
\[
R\tilde{R} = 1, \quad Rn\tilde{R} = n
\]

\begin{thm} If $R = \exp(B)$ and $B$ is a bivector of the form 
given in lemma
\ref{lem:bk} then $R\tilde{R} = 1$.
\end{thm}
\begin{proof}
Consider the twist form of $\exp(B)$ from equation \ref{eqn:twistform}
\[
R = \exp(B) =
\tau(\phi, P, - t_\perp) + \sinc\left(\frac{\phi}{2}\right)\frac{t_\parallel n}{2}
\]
and make use of our knowledge that $\tau(\phi, P, - t_\perp)$ is a rotor.
Hence,
\begin{eqnarray*}
R\tilde{R} & = & \tau(\phi, P, - t_\perp)\tilde{\tau}(\phi, P, - t_\perp)
+ \sinc^2\left(\frac{\phi}{2}\right)
\frac{t_\parallel n^2 t_\parallel}{4}\\
&& + \ \sinc\left(\frac{\phi}{2}\right)
\left[ \tau(\phi, P, - t_\perp)nt_\parallel + 
       t_\parallel n\tilde{\tau}(\phi, P, - t_\perp) \right] \\
& = & 1 + 0 + \sinc\left(\frac{\phi}{2}\right)
\left[ T + \tilde{T} \right]
\end{eqnarray*}
where $T = \tau(\phi, P, - t_\perp)nt_\parallel$.

Looking at the definition of $\tau(\phi, P, - t_\perp)$, it is clear
that it has only scalar, bivector and 4-vector components with
the bivector components being parallel to $P$ or $t_\perp n$ and
the 4-vector components being parallel to $Pt_\perp n$. When
post-multiplied by $nt_\parallel$ to form $T$, the 4-vector component
goes to zero (since $n^2 = 0$) as does the bivector component
parallel to $t_\perp n$ and so we are left with $T$ having only
components parallel to $nt_\parallel$ and $Pnt_\parallel$. 
We may now express $T$ as
\[
T = \alpha nt_\parallel + \beta Pnt_\parallel
\]
where $\alpha$ and $\beta$ are suitably valued scalars. Hence
\[
T + \tilde{T} = \alpha \left[ nt_\parallel + t_\parallel n \right]
+ \beta \left[ Pnt_\parallel + t_\parallel n\tilde{P} \right] 
= 0 + \beta n \left[ Pt_\parallel - t_\parallel \tilde{P} \right]
\]

By considering two basis vectors of $P$, $a$ and $b$, such
that $P = ab$, $a \cdot b = 0$ and resolving $t_\parallel$ in 
terms of $a$ and $b$ it is easy to show that 
$Pt_\parallel - t_\parallel\tilde{P} = 0$ and hence
$T + \tilde{T} = 0$ giving the required result.
\end{proof}

\begin{thm} If $R = \exp(B)$ and $B$ is a bivector of the form 
given in lemma
\ref{lem:bk} then $Rn\tilde{R} = n$.
\end{thm}
\begin{proof}
Again using the twist form of $R$ from equation \ref{eqn:twistform} we have
\begin{eqnarray*}
Rn & = & \tau(\phi, P, - t_\perp)n + 
\sinc\left(\frac{\phi}{2}\right)\frac{t_\parallel n^2}{2} \\
&=& \tau(\phi, P, - t_\perp)n + 0
\end{eqnarray*}
Defining the rotation rotor $R_{(P,\phi)}$ as
\[
R_{(P,\phi)} = \cos\left(\frac{\phi}{2}\right) +
   \sin\left(\frac{\phi}{2}\right)P
\]
and substituting for the definition of the twist above gives
\[
Rn = R_{(P,\phi)} n
\]
Similarly, again using the twist form of $R$ we have
\begin{eqnarray*}
nR & = & n\tau(\phi, P, - t_\perp) + 
\sinc\left(\frac{\phi}{2}\right)\frac{nt_\parallel n}{2} \\
% & = & n\tau(\phi, P, t_\perp) - 
%\sinc\left(\frac{\phi}{2}\right)\frac{t_\parallel n^2}{2} \\
&=& n\tau(\phi, P, - t_\perp) + 0 \\
&=& n R_{(P,\phi)} \left( 1 + \frac{tn}{2} \right) \\
&=& R_{(P,\phi)} n \left( 1 + \frac{tn}{2} \right) \\
&=& R_{(P,\phi)} n 
\end{eqnarray*}
We now have that $Rn = nR$ and hence, using
$R\tilde{R} = 1$ from the previous thm, 
$Rn\tilde{R} = nR\tilde{R} = n$.
\end{proof}

\section{Method for evaluating $\ell(R)$}

We have found a form for $\exp(B)$ given that $B$ is in a particular form.
Now we seek a method to take an arbitrary displacement
rotor, $R = \exp(B)$ and re-construct the original $B$. Should there exist
a $B$ for all possible $R$, we will show that our initial assumption
that all displacement rotors can be formed from a single exponentiated bivector
of special form is valid. We shall term this initial bivector
the \emph{generator} rotor (to draw a parallel with Lie algebras).

We can obtain the following identities for $B=(\phi / 2) P + tn / 2$ by simply considering
the grade of each component of the exponential:
\begin{eqnarray*}
\left< R \right>_0 & = & \cos\left(\frac{\phi}{2}\right) \\
\left< R \right>_2 & = & \sin\left(\frac{\phi}{2}\right) P + 
  \cos\left(\frac{\phi}{2}\right) t_\perp n + \sinc\left(\frac{\phi}{2}\right) t_\parallel n \\
\left< R \right>_4 & = & \sin\left(\frac{\phi}{2}\right) Pt_\perp n
\end{eqnarray*}

It is somewhat straightforward to reconstruct $\phi, t_\perp$ and $t_\parallel$ from these
components by partitioning a rotor as above. Once we have a method which gives the
generator $B$ for any displacement rotor $R$ we have validated our assumption.

\begin{thm}
The inverse-exponential function $\ell(R)$ is given by
\[
\ell(R) = ab + \cperp n + \cpar n
\]
where
\begin{eqnarray*}
\magof{ab} & = & \sqrt{\left| (ab)^2 \right|}  = \cos^{-1}(\left<R\right>_0) \\
ab & = & \frac{\left(\left<R\right>_2 n \right) \cdot e}
{\sinc\left(\magof{ab}\right)}\\
\cperp n & = & - \frac{ab \left<R\right>_4}
{\magof{ab}^2\sinc(\magof{ab})} \\
\cpar n & = & - \frac{ab \left<ab \left<R\right>_2\right>_2}
{\magof{ab}^2\sinc(\magof{ab})}
\end{eqnarray*}
\end{thm}
\begin{proof}
It is clear from the above that the form of
$\magof{ab}$ is correct. We thus proceed to show the remaining
equations to be true
\begin{eqnarray*}
\left<R\right>_2 & = & \cos(\magof{ab}) \, \cperp n +
\sinc(\magof{ab}) \left[ab + \cpar n\right]\\
\left<R\right>_2 n & = & \sinc(\magof{ab}) \, abn\\
\left(\left<R\right>_2 n\right) \cdot e & = & \sinc(\magof{ab}) \, ab
\end{eqnarray*}
and hence the relation for $ab$ is correct.
\begin{eqnarray*}
\left<R\right>_4 & = & \sinc(\magof{ab}) \, ab\cperp n \\
ab \left<R\right>_4 & = & -\magof{ab}^2 \sinc(\magof{ab}) \, \cperp n 
\end{eqnarray*}
and hence the relation for $\cperp n$ is correct.
\begin{eqnarray*}
\left<R\right>_2 & = & \cos(\magof{ab}) \, \cperp n +
\sinc(\magof{ab}) \left[ab + \cpar n\right]\\
ab \left<R\right>_2 & = & \cos(\magof{ab}) \, ab\cperp n +
\sinc(\magof{ab}) \left[ab \cpar n - \magof{ab}^2\right]\\
\left<ab \left<R\right>_2\right>_2 & = & 
\sinc(\magof{ab}) \, ab \cpar n
\end{eqnarray*}
and hence the relation for $\cpar n$ is correct.
\end{proof}

\section{Limitations of Current Form}


\section{Mapping Generators to Matrices}

Although the representation of a rotor as an exponentiated generator bivector
is convenient mathematically and useful for smooth pose interpolation
and mesh deformation, as will be presented later, it is somewhat cumbersome
to integrate into an existing graphical pipeline. Most graphics hardware and
nearly all graphics APIs represent rigid-body transformations as $4 \times 4$ matrices.
Specifically given the projective mapping from a three-dimensional vector $\mathbf{x}$ to
its homogenous representation,
\[
\mathbf{x} \mapsto \left[ \begin{array}{c}
w \mathbf{x} \\ w
\end{array}\right]
\]
where $w$ is some arbitrary non-zero scalar, a rigid body transform can be represented as
\[
 \left[ \begin{array}{c}
w \mathbf{x} \\ w
\end{array}\right]
\mapsto
 \mathcal{R}\left[ \begin{array}{c}
w \mathbf{x} \\ w
\end{array}\right]
\]
and
\[
\mathcal{R} = \left[
\begin{array}{cc}
\mathbf{A} & \mathbf{t} \\
                0 & 1
\end{array}
\right].
\]
Here $\mathbf{A}$ is an orthonormal $3 \times 3$ rotation matrix and $\mathbf{t}$ is some
translation vector.

Due to the common nature of such a representation it would be advantageous
to have some method of mapping between the coneniently linear space of generators
to the decidedly non-linear space of these $4 \times 4$ matrices. In this section
we shall develop such a method. Note that we shall only be working in three-dimensions due
to the limitations of the matrix representation rather than the exponentiated
generator representation.

Recall that we represent a rotor, $R$, as $R = \exp(B)$ where $B$ is a bivector
The generator bivector, $B$, may itself be
parameterised in terms of a spatial bivector $P$ normalised such that
$P^2 = -1$, a scalar $\phi$ and a spactial vector $t$
as in lemma \ref{lem:bk}.
Letting $P = p_1 e_{12} + p_2 e_{23} + p_3 e{31}$ and
$t = t_1 e_1 + t_2 e_2 + t_3 e_3$ we may represent $B$ via the
vector $\mathbf{b}$:
\[
\mathbf{b} = [ p_1 \; p_2 \; p_3 \; t_1 \; t_2 \; t_3 ]^T.
\]

Using this generator representation is useful since any vector
$\mathbf{b} \in {\mathbb R}^6$ will represent a valid generator and
hence a valid rotor.

%the $4\times4$ matrix representation is useful for existing graphics
%algorithms. This note aims to develop an algorithm for converting from
%one to another with the proviso that 

It is also worth noting that this method of converting from a matrix representation
to a generator is lossy in so much as the matrix representation cannot uniquely
represent rotations by more the $2\pi$.

\subsection{Method}

We shall attempt to linearise the application of a rotor associated
with a generator to a point by defining an appropriate linear function
$h(\cdot)$.

\begin{definition}
The function $h(\phi, P, t, p, \lambda)$ is defined, for $\lambda = 1$ as
\[
h(\phi, P, t, p, 1) = F^{-1} \left( R F(p) \tilde{R} \right)
\]
where $R = \exp(B)$, $B = \phi P+tn$ and $P, \phi$ and $t$ are
as defined in lemma \ref{lem:bk}. $F(\cdot)$ is the usual vector 
to null-vector mapping.
\end{definition}

It is easy, if somewhat tedious, to show by direct expansion and comparison of terms that
an expression for $h(\cdot)$ which matches the definition above is
\begin{align}
h(\phi, P, t, p, \lambda) &=c^2p - s^2PpP - sc\left[pP - Pp\right] \nonumber \\
&\quad+ \lambda\left[ 
 \frac{kc+1}{2} t + \frac{kc-1}{2} PtP
- \frac{sk}{2} (tP - Pt)
\right] \label{eqn:defnh}
\end{align}
where $s = \sin(\phi/2)$, $c = \cos(\phi/2)$ and $k = \textrm{sinc}(\phi/2)$.

\begin{definition}
The function $\mathbf{v}(x)$ maps the $m$-dimensional vector $x$ to its column-vector
representation,
\[
\mathbf{v}(x) = \left[
\begin{array}{c}
x \cdot e_1 \\ x \cdot e_2 \\ \vdots \\ x \cdot e_m
\end{array} 
\right].
\]
\end{definition}

It is clear by inspection that the function $h(\cdot)$ is linear in $(p,\lambda)$ 
therefore we can find some $3\times4$ matrix $\mathcal{H}(\phi, P, t)$, such that
\begin{equation}
\mathbf{e}^T 
 \mathcal{H}(\phi, P, t) \left[
\begin{array}{c}
\mathbf{v}(p) \\ 1
\end{array} 
\right] = h(\phi, P, t, p, 1) \label{eqn:hi}
\end{equation}
where $\mathbf{e}^T = \left[ e_1 \; e_2 \; e_3 \right]$.

Comparing the action of $\mathcal{H}$ and the form of $\left[ \mathbf{v}(p) \; 1 \right]^T$
to the discussion of $4\times4$ transformation matrixes above it is easy to
see that the mapping $p \mapsto h(\phi, P, t, p, 1)$ is equivalent to
\[
\left[
\begin{array}{c}
\mathbf{v}(p) \\ 1
\end{array} 
\right]
\mapsto
\mathcal{R}
\left[
\begin{array}{c}
\mathbf{v}(p) \\ 1
\end{array} 
\right]
\]
with
\[
\mathcal{R} = \left[
\begin{array}{cccc}
\multicolumn{4}{c}{\mathcal{H}} \\
                 0 & 0 & 0 & 1 
\end{array}
\right].
\]

Mapping a given generator, parameterised in terms of $\phi, P$ and $t$ therefore
requires finding a closed form of $\mathcal{H}$ given $h(\cdot)$.

\subsection{Finding $\mathcal{H}$ from a generator}

In this section we shall develop a specific homomorphism from the specific
aspects of Geometric Algebra used to evaluate $h(\cdot)$ and linear algebra with
a view to inducing a form for $\mathcal{H}$.

\begin{definition}
Define the resolution of a bivector $A$ onto the orthonormal basis
set $\{e_{12}, e_{23}, \cdots\}$ as the set of scalars $\{a_{12}, a_{23}, \cdots\}$ where
\[A = a_{12}e_{12} + a_{23}e_{23} + \cdots.\]
\end{definition}

\begin{definition}
Define the resolution of a vector $b$ onto the orthonormal basis
set $\{e_{1}, e_{2}, \cdots\}$ as the set of scalars $\{b_{1}, b_{2}, \cdots\}$ where
\[b = b_1e_1 + b_2e_2 + \cdots.\]
\end{definition}

\begin{definition}
Define the function $\mathbf{f}_1(A,b)$,
       with $A$ a three-dimensional
bivector and $b$ a three-dimensional vector,
as
\[
\mathbf{f}_1(A,b) =
\left[ 
\begin{array}{ccc}
0 & a_{12} & - a_{31} \\
- a_{12} & 0 & a_{23}\\
a_{31} & - a_{23} & 0 
\end{array} 
\right]  
\left[ 
\begin{array}{c}
b_1 \\ b_2 \\ b_3
\end{array} 
\right].\]
\end{definition}

\begin{definition}
Define the function $f_2(A,b)$,
       with $A$ a three-dimensional
bivector and $b$ a three-dimensional vector,
       as
\[
f_2(A,b) = (a_{12}b_{3} + a_{23}b_1 + a_{31}b_2).
\]
\end{definition}

\begin{cor}
\label{lem:ABandBA}
Given  $A$ a three-dimensional
bivector and $b$ a three-dimensional vector
\[
bA - Ab = -
\left[ e_1 \; e_2 \; e_3 \right]
2\mathbf{f}_1(A,b).
\]
\begin{proof}
With the definitions for resolving $A$ and $b$ above it is trivial to show by direct expansion
over an orthonormal basis that
\[
Ab =
f_2(A,b)\;e_{123} +
\left[ e_1 \; e_2 \; e_3 \right]
 \mathbf{f}_1(A,b)
\]
and
\[
bA =
f_2(A,b)\;e_{123} - 
\left[ e_1 \; e_2 \; e_3 \right]
\mathbf{f}_1(A,b)
\]
The desired result is then clear by substitution.
\end{proof}
\end{cor}

\begin{definition}
Define $\mathbf{M}_1(A)$ to be a matrix dependent on a three-dimensional bivector $A$,
\[
\mathbf{M}_1(A) = \left[ 
\begin{array}{ccc}
0 & a_{12} & - a_{31} \\
- a_{12} & 0 & a_{23}\\
a_{31} & - a_{23} & 0 
\end{array} 
\right].
%\quad\mathrm{and}\quad
%\mathbf{v}(b) = \left[ 
%\begin{array}{c}
%b_1 \\
%b_2 \\
%b_3 
%\end{array} 
%\right]  
\]
\end{definition}

\begin{cor}
Equation \ref{eqn:defnh} is equivalent to
\begin{align*}
h(\phi, P, t, p, \lambda) &= c^2\;\mathbf{e}^T\mathbf{v}(p) - s^2PpP + 2sc\;\mathbf{e}^T\mathbf{M}_1(P)\mathbf{v}(p) \\
&\quad+ \lambda\left[ 
 \frac{kc+1}{2} \mathbf{e}^T\mathbf{v}(t) + \frac{kc-1}{2} PtP
+ sk\;\mathbf{e}^T\mathbf{M}_1(P)\mathbf{v}(t)
\right].
\end{align*}
\begin{proof}
Direct substitution and application of lemma \ref{lem:ABandBA}.
\end{proof}
\end{cor}

\begin{definition}
Define $\mathbf{M}_2(A)$ to be a vector dependent on a three-dimensional bivector $A$,
\[
\mathbf{M}_2(A)  =
\left[
\begin{array}{ccc}
a^2_{12} - a^2_{23} + a^2_{31} &  - 2a_{23}a_{31} & - 2a_{12}a_{23} \\
- 2a_{23}a_{31} & a^2_{12} + a^2_{23} - a^2_{31} & - 2a_{12}a_{31}  \\
- 2a_{12}a_{23} & - 2a_{12}a_{31} &  -a^2_{12} + a^2_{23} + a^2_{31} 
\end{array}
\right].
\]
\end{definition}

\begin{cor}
Given a three-dimensional bivector $A$ and a three-dimensional vector $b$,
\[
AbA = \mathbf{e}^T \mathbf{M}_2(A) \mathbf{v}(b).
\]
\begin{proof}
Clear by substitution and expansion.
\end{proof}
\end{cor}

\begin{lemma}
\label{lem:finalh}
An equivalent form for $h(\cdot)$ as given in equation \ref{eqn:defn} is
\begin{align*}
h(\phi, P, t, p, \lambda) &= 
\mathbf{e}^T \left[ 
 c^2\;\mathbf{v}(p) - s^2\;\mathbf{M}_2(P)\mathbf{v}(p) + 2sc\;\mathbf{M}_1(P)\mathbf{v}(p) 
\right] \\
&\quad+ \lambda\mathbf{e}^T\left[ 
 \frac{kc+1}{2} \mathbf{v}(t) + \frac{kc-1}{2} \;\mathbf{M}_2(P)\mathbf{v}(t)
+ sk\;\mathbf{M}_1(P)\mathbf{v}(t)
 \right].
\end{align*}
\begin{proof}
Substitute the above corollarys into $h(\phi, P, t, p,\lambda)$ to obtain
\begin{align*}
h(\phi, P, t, p, \lambda) &= 
c^2\;\mathbf{e}^T\mathbf{v}(p) - s^2\;\mathbf{e}^T\mathbf{M}_2(P)\mathbf{v}(p) + 2sc\;\mathbf{e}^T\mathbf{M}_1(P)\mathbf{v}(p) \\
&\quad+ \lambda\left[ 
 \frac{kc+1}{2} \mathbf{e}^T\mathbf{v}(t) + \frac{kc-1}{2} \;\mathbf{e}^T\mathbf{M}_2(P)\mathbf{v}(t)
+ sk\;\mathbf{e}^T\mathbf{M}_1(P)\mathbf{v}(t)
 \right]
\end{align*}
and rearrange.
\end{proof}
\end{lemma}

\begin{definition}
\label{def:m3}
Define $\mathbf{M}_3(A)$ to be a matrix dependent on a three-dimensional bivector $A$,
\[
\mathbf{M}_3(A) = \frac{kc+1}{2} \mathbf{I}_3 
+ \frac{kc-1}{2} \;\mathbf{M}_2(A) + sk\;\mathbf{M}_1(P)
\]
where  $\mathbf{I}_3$ is the $3\times3$ identity matrix.
\end{definition}

\begin{thm}
The $3\times4$ matrix $\mathcal{H}$ may be found directly from a
generator $B=\phi P + tn$ as
\[
\mathcal{H} = \left[
 c^2\mathbf{I}_3 - s^2\;\mathbf{M}_2(P) + 2sc\;\mathbf{M}_1(P) \; ; \;
 \mathbf{M}_3(P)\mathbf{v}(t)
\right]
\]
where  $\mathbf{I}_3$ is the $3\times3$ identity matrix.
\begin{proof}
Clear by comparison of lemma \ref{lem:finalh} with definition \ref{def:m3}.
\end{proof}
\end{thm}

\noindent The required $4\times4$ matrix $\mathcal{R}$ can now easily be found from $\mathcal{H}$.

\subsection{Finding the generator from $\mathcal{H}$}

Firstly represent $\mathcal{H}$ as
\[
\mathcal{H} = [ \mathbf{A}\; ; \; \mathbf{c} ]
\]
where 
\[\mathbf{A} = c^2\mathbf{I}_3 - s^2\;\mathbf{M}_2(P) + 2sc\;\mathbf{M}_1(P)\]
and
\begin{equation}
\mathbf{c} = \mathbf{M}_3(P)\mathbf{v}(t). \label{eqn:b}
\end{equation}
Both $\mathbf{A}$ and $\mathbf{c}$ may be extracted from $\mathcal{R}$ easily.
Given the anti-symmetric and symmetric nature
of $\mathbf{M}_1(P)$ and $\mathbf{M}_2(P)$ it is clear that
\begin{align*}
\mathbf{A} + \mathbf{A}^T &= 
2\left[ c^2\mathbf{I}_3 - s^2\;\mathbf{M}_2(P) \right] \\
\mathbf{A} - \mathbf{A}^T &= 
4sc\;\mathbf{M}_1(P).
\end{align*}
If $sc \ne 0$ then we may recover $P$ by extracting elements of 
$\mathbf{A} - \mathbf{A}^{T}$ and renormalising. If $sc = 0$ then either
$s = 0$ or $c = 0$. If $s = 0$ it implies $\phi = 2n\pi$, $c = 1$ and 
therefore that 
$\mathbf{A} + \mathbf{A}^{T}$ should be the identity matrix and
we are free to choose $P$ as we wish. If $c = 0$ then $s = \pm 1$
and $\mathbf{A} + \mathbf{A}^{T} = 2 \mathbf{M}_2(P)$. We can then
extract $P$ from $\mathbf{M}_2(P)$. The sign of $s$, in this case, is arbitrary.

Assuming we have estimates for $s$, $k$ and $c$ from above, we may
estimate $\mathbf{M}_3(P)$ directly and hence recover
\[
\mathbf{v}(t) = \mathbf{M}^{-1}_3(P) \mathbf{c}.
\]
In practice we might wish to use LU decomposition or similar rather
than computing the matrix inverse if we deal with spaces with higer
dimensionality. Finally, given $s$, $c$ and $k$, an estimate for 
$\phi$ can be made. 
