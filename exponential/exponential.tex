\chapter{Rotors as Exponentiated Bivectors}

Referring to the displacement rotors presented above, we
see that all of them have a common form; they are all exponentiated bivectors.
Rotations are generated by bivectors with no component parallel to
$n$ and translations by a bivector with no components perpendicular to $n$. We
may thus postulate that all displacement rotors\footnote{There also exist dilation rotors but 
these will not be discussed in this paper.} can be expressed as
\[
R = \exp(B)
\]
where $B$ is the sum of two bivectors, one formed from two vectors which have no
components parallel to $e$ or $\bar{e}$. The other is formed from the outer product 
of vectors with no components parallel to $e$ or $\bar{e}$ and $n$. The effect of this
is to separate the basis bivectors of $B$ into one with components of the form $e_i \wedge e_j$
and one with components of the form $e_i \wedge e$ and $e_i \wedge \bar{e}$.

We shall proceed assuming that all displacement rotors can be written as
the exponentiation of a bivector of the form $B = ab + cn$ where $a$, $b$ and
$c$ are independent of $n$, i.e. if $n \in \mathcal{A}(m+1,1)$ then $\{a,b,c\} \in \mathbb{R}^m$.
It is clear that the set of all $B$ is some
linear sub-space of all the bivectors.

We now suppose that we may interpolate rotors by defining
some function $\ell(R)$ which acts upon rotors to give the generating
bivector element. We then perform direct interpolation of these generators. We postulate that
direct interpolation of these bivectors, as in the reformulation of quaternionic interpolation
above, will give some smooth interpolation between the displacements.
It is therefore a defining property of $\ell(R)$ that
\begin{equation}
R \equiv \exp(\ell(R))
\end{equation}
and so $\ell(R)$ may be considered as to act as a logarithm-like function in this context.
It is worth noting that $\ell(R)$ does not possess all the properties usually associated with logarithms, notably that, since $\exp(A)\exp(B)$ is not generally equal to $\exp(B)\exp(A)$ in non-commuting algebras,
$\ell(\exp(A)\exp(B))$ cannot be equal to $A + B$ except in special cases.

To avoid the the risk of assigning more properties to $\ell(R)$ than we have shown, we shall
resist the temptation to denote the function $\log(R)$. The most obvious property of $\log(\cdot)$ that
$\ell(\cdot)$ doesn't possess is $\log(AB) = \log(A) + \log(B)$. This is clear since the geometric product
is not commutative in general whereas addition is.

\section{Form of $\exp(B)$ in Euclidean space}
\label{subsec:form}

\begin{lemma}
\label{lem:bk}
If $B$ is of the form $B=\phi P+tn$ where 
$t \in \mathbb{R}^n$, $\phi$ is some scalar and $P$ is a 2-blade 
where $P^2 = -1$ then, for any $k \in \mathbb{Z}^+$, 
\[
B^{k}=\phi^k P^{k}+\alpha _{k}^{(1)}\phi Ptn+
\alpha _{k}^{(2)}\phi^2 PtnP+\alpha _{k}^{(3)}\phi tnP+\alpha _{k}^{(4)}tn
\]
with the following recurrence relations for $\alpha _{k}^{(\cdot )}$,
$k>0$ 

\begin{centering}

\begin{tabular}{r@{$\ =\ $}lr@{$\ =\ $}l}
$\alpha _{k}^{(1)}$ & $- \phi^2 \alpha _{k-1}^{(2)}$ &
$\alpha _{k}^{(2)}$ & $\alpha _{k-1}^{(1)}$\\
$\alpha _{k}^{(3)}$ & $\alpha _{k-1}^{(4)}$ &
$\alpha _{k}^{(4)}$ & $\phi^{k-1}P^{k-1} - \phi^2 \alpha_{k-1}^{(3)}$
\end{tabular}

\end{centering}

\noindent with 
$\alpha _{0}^{(1)}=\alpha _{0}^{(2)}=
\alpha _{0}^{(3)}=\alpha _{0}^{(4)}=0$.
\end{lemma}
\begin{proof}
Firstly note that the thm is trivially provable by direct 
substitution for the cases $k=0$ and $k=1$. We thereafter seek a 
proof by induction.

Assuming the expression for $B^{k-1}$ is correct, we post-multiply
by $\phi P+tn$ to obtain
\begin{eqnarray*}
B^k & = & \phi^k P^k + \alpha_{k-1}^{(1)}\phi^2 PtnP + 
          \alpha_{k-1}^{(2)}\phi^3 PtnP^2 + \alpha_{k-1}^{(3)}\phi^2 tnP^2 + \\
    &   & \alpha_{k-1}^{(4)}\phi tnP + \phi^{k-1} P^{k-1} tn + \alpha_{k-1}^{(1)}\phi P(tn)^2 +
          \alpha_{k-1}^{(2)}\phi^2 PtnPtn + \\
    &   & \alpha_{k-1}^{(3)}\phi tnPtn +
	  \alpha_{k-1}^{(4)}(tn)^2
\end{eqnarray*}

Substituting $P^2 = -1$, $(tn)^2 = - tn^2t = 0$ and noting that
$nPt = - Ptn$ leading to $tnPtn = - tPtn^2 = 0$

\begin{eqnarray*}
B^k & = & \phi^k P^k + \alpha_{k-1}^{(1)}\phi^2 PtnP -
          \alpha_{k-1}^{(2)}\phi^3 Ptn - \alpha_{k-1}^{(3)}\phi^2 tn + \\
    &   & \alpha_{k-1}^{(4)}\phi tnP + \phi^{k-1} P^{k-1} tn \\
    & = & \phi^k P^k - (\alpha_{k-1}^{(2)}\phi^2)\phi Ptn +
          \alpha_{k-1}^{(1)}\phi^2 PtnP + \\
    &   & \alpha_{k-1}^{(4)}\phi tnP +
	  (\phi^{k-1} P^{k-1}  - \alpha_{k-1}^{(3)}\phi^2) tn
\end{eqnarray*}

Equating like coefficients we obtain the required recurrence relations.
\end{proof}

\begin{lemma}
\label{lem:bkexp}
Assuming the form of $B$ given in lemma \ref{lem:bk}, for 
$k\in \mathbb{Z}^{+}$,\[
B^{2k}=(-1)^k\phi^{2k}-k(-1)^k\phi^{2k-1}[tnP + Ptn]
\]and\[
B^{2k+1}=(-1)^k\phi^{2k+1}P + k \phi^{2k} (-1)^k [ tn - PtnP ] + (-1)^k\phi^{2k} tn
\]
\end{lemma}
\begin{proof}
Starting from $\alpha _{0}^{(.)}=0$ it is clear that the recurrence
relations above imply that $\alpha _{k}^{(1)}=\alpha _{k}^{(2)}=0\; \forall \: k \ge 0$.
Substituting $\alpha _{k}^{(3)}=\alpha _{k-1}^{(4)}$ it is trivial to show
that the relation for $\alpha _{k}^{(4)}$ is satisfied by \[
\alpha _{k}^{(4)}=\begin{cases}
 \frac{k}{2}(\phi P)^{k-1} & k\textrm{ even,}\\
 \frac{k+1}{2}(\phi P)^{k-1} & k\textrm{ odd.}\end{cases}\]
When substituted into the expression for $B^{k}$, we obtain the
result stated above.
\end{proof}

\begin{thm}
\label{lem:exp}
If $B$ is a bivector of the form given in thm \ref{lem:bk}
then, defining 
$t_\parallel$ as the component of $t$ lying in the plane of $P$ 
and $t_\perp = t - t_\parallel$,
\[
\exp(B) = \left[ \cos(\phi) + \sin(\phi) P \right] \left[ 1 + t_\perp n \right] + \sinc(\phi) t_\parallel n
\]
\end{thm}
\begin{proof}
Consider the power series expansion of $\exp (B)$,
\[
\exp (B)=\sum _{k=0}^{\infty }\frac{B^{k}}{k!}=\sum _{k=0}^{\infty }\left[\frac{B^{2k}}{(2k)!}+\frac{B^{2k+1}}{(2k+1)!}\right]\]
Substituting the expansion for $B^{2k}$ and $B^{2k+1}$ from 
lemma \ref{lem:bkexp}
\begin{align*}
\exp (B)= & \sum _{k=0}^{\infty }\left[
 \frac{
   (-1)^k\phi^{2k}
 }{(2k)!} - k \frac{
   (-1)^k\phi^{2k-1}
 }{(2k)!} \left(tnP + Ptn\right)
\right]\\
+ & \sum _{k=0}^{\infty }\left[
 \frac{
   (-1)^k\phi^{2k}
 }{(2k+1)!} \left(\phi P + tn\right) + 
 k\frac{
   (-1)^k \phi^{2k}
 }{(2k+1)!} \left( tn - PtnP \right)\right]
\end{align*}
We now substitute the following power-series representations

\begin{centering}

%\[
%\begin{array}{r@{=}l@{\quad}r@{=}l}
%\cos(z) & \sum_{k=0}^\infty \frac{(-1)^k z^{2k}}{(2k)!} &
%\sinc(z) & \sum_{k=0}^\infty \frac{(-1)^k z^{2k}}{(2k+1)!} \\
%- z \sin(z) & \sum_{k=0}^\infty 2k \frac{(-1)^k z^{2k}}{(2k)!} &
%\cos(z) - \sinc(z) & \sum_{k=0}^\infty 2k \frac{(-1)^k z^{2k}}{(2k+1)!}
%\end{array}
%\]

\begin{tabular}{r@{$\ =\ $}l@{$\quad$}r@{$\ = \ $}l}
\multicolumn{4}{l}{\vspace{0.1cm}} \\
$\cos(z)$ & $\sum_{k=0}^\infty \frac{(-1)^k z^{2k}}{(2k)!}$ &
$\sinc(z)$ & $\sum_{k=0}^\infty \frac{(-1)^k z^{2k}}{(2k+1)!}$ \\
\multicolumn{4}{l}{\vspace{0.1cm}} \\
$- z \sin(z)$ & $\sum_{k=0}^\infty 2k \frac{(-1)^k z^{2k}}{(2k)!}$ &
$\cos(z) - \sinc(z)$ & $\sum_{k=0}^\infty 2k \frac{(-1)^k z^{2k}}{(2k+1)!}$ \\
\multicolumn{4}{l}{\vspace{0.1cm}} \\
\end{tabular}

\end{centering}

\noindent to obtain
\begin{align*}
\exp(B) = & 
  \cos \phi + \sin(\phi) \frac{1}{2} (tnP + Ptn) + \sinc(\phi) (\phi P + tn) \\
+ & \frac{1}{2} \left[ \cos(\phi) - \sinc(\phi) \right] (tn - PtnP)
\end{align*}
By considering parallel and perpendicular components of $t$ with
respect to the plane of $P$ is easy to verify that
$tnP + Ptn = 2 Pt_\perp n$ and $PtnP = (t_\parallel - t_\perp)n$ hence
\begin{align*}
\exp(B) = & 
  \cos \phi + \sin(\phi) P t_\perp n + \sinc(\phi) (\phi P + tn) + \left[ \cos(\phi) - \sinc(\phi) \right] t_\perp n \\
  = & \cos (\phi) \left[ 1 + t_\perp n \right] +
  \sin(\phi) P \left[ 1 + t_\perp n \right] + \sinc(\phi) t_\parallel n \\
  = & \left[ \cos(\phi) + \sin(\phi) P \right] \left[ 1 + t_\perp n \right] + \sinc(\phi) t_\parallel n 
\end{align*}
as required.
\end{proof}

\begin{definition}
A \emph{twist} is a rotor whose action is to rotate by $\psi$ in the 
plane of $P$ whilst translating along a vector $a$ perpendicular to
the plane of $P$. It may therefore be 
defined by the rotor 
\[
\tau(\psi, P, a) =
 \left[ \cos\left(\frac{\psi}{2}\right) +
   \sin\left(\frac{\psi}{2}\right)P
 \right]
 \left[
   1 + \frac{na}{2}
 \right]
\]
where $\psi$ is a scalar, $P$ is a $2$-blade normalised such that 
$P^2 = -1$ and $a$ is some vector satisfying $a \cdot n = a \cdot P = 0$.
\end{definition}

\begin{lemma}
The exponentiation function may be re-expressed using a twist
\[
\exp\left(\frac{\psi}{2}P + \frac{tn}{2}\right) =
\left[ 1 + \sinc\left(\frac{\psi}{2}\right)\frac{t_\parallel n}{2} \tilde{\tau}(\psi, P, - t_\perp) \right]
\tau(\psi, P, - t_\perp)
\]
\end{lemma}
\begin{proof}
We firstly substitute our definition of a twist into our form for the exponential
\begin{equation}
\exp\left(\frac{\psi}{2}P + \frac{tn}{2}\right) =
\tau(\psi, P, - t_\perp) + \sinc\left(\frac{\psi}{2}\right)\frac{t_\parallel n}{2}
\label{eqn:twistform}
\end{equation}
noting that, since twists are rotors, $\tau( \cdot ) \tilde{\tau}(\cdot) = 1$, it is
trivial to verify that the required expression is equivalent to this form of the exponential.
\end{proof}

\begin{lemma}
The expression
\[
 1 + \sinc\left(\frac{\psi}{2}\right)\frac{t_\parallel n}{2} \tilde{\tau}(\psi, P, - t_\perp)
\]
is a rotor which acts to translate along a vector $t'_\parallel$ given by
\[
t'_\parallel = - \sinc\left(\frac{\psi}{2}\right)
t_\parallel
\left(
\cos\left(\frac{\psi}{2}\right) -
\sin\left(\frac{\psi}{2}\right) P 
\right)
\]
\end{lemma}
\begin{proof}
The expression above may be obtained by substituting for the twist in the initial expression and simplifying. 
It is clearly a vector since multiplying $t_\parallel$ on the left by $P$ is just a rotation by $\pi / 2$ in the plane
of $P$.
\end{proof}

We have now developed the required thms and tools to discuss the
action of the rotor
\[
R = \exp\left(
\frac{\psi}{2} P + \frac{tn}{2}
\right)
\]
It translates along a vector $t_\perp$ which is the component of $t$ which does not lie in the
plane of $P$, rotates by $\psi$ in the plane of $P$ and finally translates along 
$t'_\parallel$ which is given by
\[
t'_\parallel =- \sinc\left(\frac{\psi}{2}\right)
t_\parallel
\left(
\cos\left(\frac{\psi}{2}\right) -
\sin\left(\frac{\psi}{2}\right) P 
\right)
\]
which is the component of $t$ lying in the
plane of $P$, rotated by $\psi/2$ in that plane.

\section{Checking $\exp(B)$ is a rotor}

It is sufficient to check that $\exp(B)$ satisfies the following
properties of a rotor $R$. % in Euclidean space
\[
R\tilde{R} = 1, \quad Rn\tilde{R} = n
\]

\begin{thm} If $R = \exp(B)$ and $B$ is a bivector of the form 
given in lemma
\ref{lem:bk} then $R\tilde{R} = 1$.
\end{thm}
\begin{proof}
Consider the twist form of $\exp(B)$ from equation \ref{eqn:twistform}
\[
R = \exp(B) =
\tau(\psi, P, - t_\perp) + \sinc\left(\frac{\psi}{2}\right)\frac{t_\parallel n}{2}
\]
and make use of our knowledge that $\tau(\psi, P, - t_\perp)$ is a rotor.
Hence,
\begin{eqnarray*}
R\tilde{R} & = & \tau(\psi, P, - t_\perp)\tilde{\tau}(\psi, P, - t_\perp)
+ \sinc^2\left(\frac{\psi}{2}\right)
\frac{t_\parallel n^2 t_\parallel}{4}\\
&& + \ \sinc\left(\frac{\psi}{2}\right)
\left[ \tau(\psi, P, - t_\perp)nt_\parallel + 
       t_\parallel n\tilde{\tau}(\psi, P, - t_\perp) \right] \\
& = & 1 + 0 + \sinc\left(\frac{\psi}{2}\right)
\left[ T + \tilde{T} \right]
\end{eqnarray*}
where $T = \tau(\psi, P, - t_\perp)nt_\parallel$.

Looking at the definition of $\tau(\psi, P, - t_\perp)$, it is clear
that it has only scalar, bivector and 4-vector components with
the bivector components being parallel to $P$ or $t_\perp n$ and
the 4-vector components being parallel to $Pt_\perp n$. When
post-multiplied by $nt_\parallel$ to form $T$, the 4-vector component
goes to zero (since $n^2 = 0$) as does the bivector component
parallel to $t_\perp n$ and so we are left with $T$ having only
components parallel to $nt_\parallel$ and $Pnt_\parallel$. 
We may now express $T$ as
\[
T = \alpha nt_\parallel + \beta Pnt_\parallel
\]
where $\alpha$ and $\beta$ are suitably valued scalars. Hence
\[
T + \tilde{T} = \alpha \left[ nt_\parallel + t_\parallel n \right]
+ \beta \left[ Pnt_\parallel + t_\parallel n\tilde{P} \right] 
= 0 + \beta n \left[ Pt_\parallel - t_\parallel \tilde{P} \right]
\]

By considering two basis vectors of $P$, $a$ and $b$, such
that $P = ab$, $a \cdot b = 0$ and resolving $t_\parallel$ in 
terms of $a$ and $b$ it is easy to show that 
$Pt_\parallel - t_\parallel\tilde{P} = 0$ and hence
$T + \tilde{T} = 0$ giving the required result.
\end{proof}

\begin{thm} If $R = \exp(B)$ and $B$ is a bivector of the form 
given in lemma
\ref{lem:bk} then $Rn\tilde{R} = n$.
\end{thm}
\begin{proof}
Again using the twist form of $R$ from equation \ref{eqn:twistform} we have
\begin{eqnarray*}
Rn & = & \tau(\psi, P, - t_\perp)n + 
\sinc\left(\frac{\psi}{2}\right)\frac{t_\parallel n^2}{2} \\
&=& \tau(\psi, P, - t_\perp)n + 0
\end{eqnarray*}
Defining the rotation rotor $R_{(P,\psi)}$ as
\[
R_{(P,\psi)} = \cos\left(\frac{\psi}{2}\right) +
   \sin\left(\frac{\psi}{2}\right)P
\]
and substituting for the definition of the twist above gives
\[
Rn = R_{(P,\psi)} n
\]
Similarly, again using the twist form of $R$ we have
\begin{eqnarray*}
nR & = & n\tau(\psi, P, - t_\perp) + 
\sinc\left(\frac{\psi}{2}\right)\frac{nt_\parallel n}{2} \\
% & = & n\tau(\psi, P, t_\perp) - 
%\sinc\left(\frac{\psi}{2}\right)\frac{t_\parallel n^2}{2} \\
&=& n\tau(\psi, P, - t_\perp) + 0 \\
&=& n R_{(P,\psi)} \left( 1 + \frac{tn}{2} \right) \\
&=& R_{(P,\psi)} n \left( 1 + \frac{tn}{2} \right) \\
&=& R_{(P,\psi)} n 
\end{eqnarray*}
We now have that $Rn = nR$ and hence, using
$R\tilde{R} = 1$ from the previous thm, 
$Rn\tilde{R} = nR\tilde{R} = n$.
\end{proof}

\section{Method for evaluating $\ell(R)$}

We have found a form for $\exp(B)$ given that $B$ is in a particular form.
Now we seek a method to take an arbitrary displacement
rotor, $R = \exp(B)$ and re-construct the original $B$. Should there exist
a $B$ for all possible $R$, we will show that our initial assumption
that all displacement rotors can be formed from a single exponentiated bivector
of special form is valid. We shall term this initial bivector
the \emph{generator} rotor (to draw a parallel with Lie algebras).

We can obtain the following identities for $B=(\psi / 2) P + tn / 2$ by simply considering
the grade of each component of the exponential:
\begin{eqnarray*}
\left< R \right>_0 & = & \cos\left(\frac{\psi}{2}\right) \\
\left< R \right>_2 & = & \sin\left(\frac{\psi}{2}\right) P + 
  \cos\left(\frac{\psi}{2}\right) t_\perp n + \sinc\left(\frac{\psi}{2}\right) t_\parallel n \\
\left< R \right>_4 & = & \sin\left(\frac{\psi}{2}\right) Pt_\perp n
\end{eqnarray*}

It is somewhat straightforward to reconstruct $\psi, t_\perp$ and $t_\parallel$ from these
components by partitioning a rotor as above. Once we have a method which gives the
generator $B$ for any displacement rotor $R$ we have validated our assumption.

\begin{thm}
The inverse-exponential function $\ell(R)$ is given by
\[
\ell(R) = ab + \cperp n + \cpar n
\]
where
\begin{eqnarray*}
\magof{ab} & = & \sqrt{\left| (ab)^2 \right|}  = \cos^{-1}(\left<R\right>_0) \\
ab & = & \frac{\left(\left<R\right>_2 n \right) \cdot e}
{\sinc\left(\magof{ab}\right)}\\
\cperp n & = & - \frac{ab \left<R\right>_4}
{\magof{ab}^2\sinc(\magof{ab})} \\
\cpar n & = & - \frac{ab \left<ab \left<R\right>_2\right>_2}
{\magof{ab}^2\sinc(\magof{ab})}
\end{eqnarray*}
\end{thm}
\begin{proof}
It is clear from the above that the form of
$\magof{ab}$ is correct. We thus proceed to show the remaining
equations to be true
\begin{eqnarray*}
\left<R\right>_2 & = & \cos(\magof{ab}) \, \cperp n +
\sinc(\magof{ab}) \left[ab + \cpar n\right]\\
\left<R\right>_2 n & = & \sinc(\magof{ab}) \, abn\\
\left(\left<R\right>_2 n\right) \cdot e & = & \sinc(\magof{ab}) \, ab
\end{eqnarray*}
and hence the relation for $ab$ is correct.
\begin{eqnarray*}
\left<R\right>_4 & = & \sinc(\magof{ab}) \, ab\cperp n \\
ab \left<R\right>_4 & = & -\magof{ab}^2 \sinc(\magof{ab}) \, \cperp n 
\end{eqnarray*}
and hence the relation for $\cperp n$ is correct.
\begin{eqnarray*}
\left<R\right>_2 & = & \cos(\magof{ab}) \, \cperp n +
\sinc(\magof{ab}) \left[ab + \cpar n\right]\\
ab \left<R\right>_2 & = & \cos(\magof{ab}) \, ab\cperp n +
\sinc(\magof{ab}) \left[ab \cpar n - \magof{ab}^2\right]\\
\left<ab \left<R\right>_2\right>_2 & = & 
\sinc(\magof{ab}) \, ab \cpar n
\end{eqnarray*}
and hence the relation for $\cpar n$ is correct.
\end{proof}

\section{Limitations of Current Form}


\section{Direct converseion between rotation matrix and generator}

We may form a rotor $R$ using some generating
bivector $B$ via
\[
R = \exp(B).
\]
In 3d we may represent any rotation and
translation rotor as a $4\times4$ matrix $\mathcal{R}$ where
\[
\mathcal{R} = \left[
\begin{array}{cc}
\mathbf{A} & \mathbf{c} \\
                0 & 1
\end{array}
\right]
\]
and $\mathbf{A}$ is some rotation matrix and $\mathbf{c}$ is some
translation vector. The generator bivector, $B$, may itself be
parameterised in terms of a spatial bivector $P$ normalised s.t.
$P^2 = -1$, a scalar $\psi$ and a spactial vector $t$:
\[
B = \frac{\psi}{2} P + \frac{nt}{2}.
\]
Letting $P = p_1 e_{12} + p_2 e_{23} + p_3 e{31}$ and
$t = t_1 e_1 + t_2 e_2 + t_3 e_3$ we may represent $B$ via the
vector $\mathbf{c}$:
\[
\mathbf{c} = [ p_1 \; p_2 \; p_3 \; t_1 \; t_2 \; t_3 ]^T.
\]

Using the generator representation is useful since any 6d vector
$\mathbf{c}$ represents a valid generator and, hence, a valid rotor yet
the $4\times4$ matrix representation is useful for existing graphics
algorithms. This note aims to develop an algorithm for converting from
one to another with the proviso that converting from a matrix representation
to a generator is lossy since the matrix representation cannot uniquely
represent rotations by more the $2\pi$.

\subsection{Theory}

Given a rotor $R$ generated by a bivector $B$ of the form above we may find
a function $h(\psi, P, t, p, \lambda)$ which applies the rotor generated
by $\psi, P$ and $t$ to the vector $p$:
\[
h(\psi, P, t, p, 1) = F^{-1} \left( R F(p) \tilde{R} \right)
\]
where $F(\cdot)$ is our usual vector to null-vector mapping.
After a little algebra\footnote{This phrase covers a multitude
  of sins...} we can see that the
following satisfies this requirement:
\begin{align}
h(\psi, P, t, p, \lambda) &=c^2p - s^2PpP - sc\left[pP - Pp\right] \nonumber \\
&\quad+ \lambda\left[ 
 \frac{kc+1}{2} t + \frac{kc-1}{2} PtP
- \frac{sk}{2} (tP - Pt)
\right] \label{eqn:defnh}
\end{align}
where $s = \sin(\psi/2)$, $c = \cos(\psi/2)$ and $k = \textrm{sinc}(\psi/2)$.
The function $h(\psi, P, t, p, \lambda)$ is clearly linear in $(p,\lambda)$ and so
we can find some $3\times4$ matrix $\mathcal{H}$, dependent on
$\psi, P$ and $t$, s.t.
\begin{equation}
\mathbf{e}^T 
 \mathcal{H} \left[
\begin{array}{c}
\mathbf{v}(p) \\ 1
\end{array} 
\right] = h(p, 1). \label{eqn:hi}
\end{equation}
where $\mathbf{e}^T = \left[ e_1 \; e_2 \; e_3 \right]$ and
$\mathbf{v} (p) = \left[ p\cdot e_1 ; p \cdot e_2 ; p \cdot e_3 \right]^T$. It is
fairly clear that
\[
\mathcal{R} = \left[
\begin{array}{cccc}
\multicolumn{4}{c}{\mathcal{H}} \\
                 0 & 0 & 0 & 1 
\end{array}
\right].
\]

\subsection{Finding $\mathcal{H}$ from a generator}

Given $A = a_{12}e_{12} + a_{23}e_{23} + a_{31}e_{31}$ and
$b = b_1e_1 + b_2e_2 + b_3e_3$, if we define
\begin{align*}
\mathbf{f}_1(A,b) &=
\left[ 
\begin{array}{ccc}
0 & a_{12} & - a_{31} \\
- a_{12} & 0 & a_{23}\\
a_{31} & - a_{23} & 0 
\end{array} 
\right]  
\left[ 
\begin{array}{c}
b_1 \\ b_2 \\ b_3
\end{array} 
\right]  
\\
f_2(A,b) &= (a_{12}b_{3} + a_{23}b_1 + a_{31}b_2) 
\end{align*}
it is easy to show directly that
\[
Ab =
f_2(A,b)\;e_{123} +
\left[ e_1 \; e_2 \; e_3 \right]
 \mathbf{f}_1(A,b)
\]
and
\[
bA =
f_2(A,b)\;e_{123} - 
\left[ e_1 \; e_2 \; e_3 \right]
\mathbf{f}_1(A,b)
\]
Hence
\[
bA - Ab = -
\left[ e_1 \; e_2 \; e_3 \right]
2\mathbf{f}_1(A,b).
\]
%Recalling $\mathbf{e}^T = \left[ e_1 \; e_2 \; e_3 \right]$
Defining
\begin{align*}
\mathbf{M}_1(A) &= \left[ 
\begin{array}{ccc}
0 & a_{12} & - a_{31} \\
- a_{12} & 0 & a_{23}\\
a_{31} & - a_{23} & 0 
\end{array} 
\right]  \quad\mathrm{and}\quad
\mathbf{v}(b) = \left[ 
\begin{array}{c}
b_1 \\
b_2 \\
b_3 
\end{array} 
\right]  
\end{align*}
we may rewrite equation \ref{eqn:defnh} as
\begin{align*}
h(\psi, P, t, p, \lambda) &= c^2\;\mathbf{e}^T\mathbf{v}(p) - s^2PpP + 2sc\;\mathbf{e}^T\mathbf{M}_1(P)\mathbf{v}(p) \\
&\quad+ \lambda\left[ 
 \frac{kc+1}{2} \mathbf{e}^T\mathbf{v}(t) + \frac{kc-1}{2} PtP
+ sk\;\mathbf{e}^T\mathbf{M}_1(P)\mathbf{v}(t)
\right].
\end{align*}
Similarly it is easy to verify that
\[
AbA = \mathbf{e}^T \mathbf{M}_2(A) \mathbf{v}(b)
\]
where
\[
\mathbf{M}_2(A)  =
\left[
\begin{array}{ccc}
a^2_{12} - a^2_{23} + a^2_{31} &  - 2a_{23}a_{31} & - 2a_{12}a_{23} \\
- 2a_{23}a_{31} & a^2_{12} + a^2_{23} - a^2_{31} & - 2a_{12}a_{31}  \\
- 2a_{12}a_{23} & - 2a_{12}a_{31} &  -a^2_{12} + a^2_{23} + a^2_{31} 
\end{array}
\right].
\]
We can now substitute into $h(\psi, P, t, p,\lambda)$ to obtain
\begin{align*}
h(\psi, P, t, p, \lambda) &= c^2\;\mathbf{e}^T\mathbf{v}(p) - s^2\;\mathbf{e}^T\mathbf{M}_2(P)\mathbf{v}(p) + 2sc\;\mathbf{e}^T\mathbf{M}_1(P)\mathbf{v}(p) \\
&\quad+ \lambda\left[ 
 \frac{kc+1}{2} \mathbf{e}^T\mathbf{v}(t) + \frac{kc-1}{2} \;\mathbf{e}^T\mathbf{M}_2(P)\mathbf{v}(t)
+ sk\;\mathbf{e}^T\mathbf{M}_1(P)\mathbf{v}(t)
 \right] \\
& = \mathbf{e}^T \left[ 
 c^2\;\mathbf{v}(p) - s^2\;\mathbf{M}_2(P)\mathbf{v}(p) + 2sc\;\mathbf{M}_1(P)\mathbf{v}(p) 
\right] \\
&\quad+ \lambda\mathbf{e}^T\left[ 
 \frac{kc+1}{2} \mathbf{v}(t) + \frac{kc-1}{2} \;\mathbf{M}_2(P)\mathbf{v}(t)
+ sk\;\mathbf{M}_1(P)\mathbf{v}(t)
 \right].
\end{align*}
Taking $\mathbf{I}_3$ as the $3\times3$ identity matrix, defining
\[
\mathbf{M}_3(P) = \frac{kc+1}{2} \mathbf{I}_3 
+ \frac{kc-1}{2} \;\mathbf{M}_2(P) + sk\;\mathbf{M}_1(P)
\]
%(note the sign change is due to 
%representing the matrix via its transpose for typograpsic convenience). 
and comparing with 
equation \ref{eqn:hi} we see that
\[
\mathcal{H} = \left[
 c^2\mathbf{I}_3 - s^2\;\mathbf{M}_2(P) + 2sc\;\mathbf{M}_1(P) \; ; \;
 \mathbf{M}_3(P)\mathbf{v}(t)
\right]
\]
which is indeed a $3\times4$ matrix as required. The matrix $\mathcal{R}$ may
now be found easily.

\subsection{Finding the generator from $\mathcal{H}$}

Firstly represent $\mathcal{H}$ as
\[
\mathcal{H} = [ \mathbf{A}\; ; \; \mathbf{c} ]
\]
where 
\[\mathbf{A} = c^2\mathbf{I}_3 - s^2\;\mathbf{M}_2(P) + 2sc\;\mathbf{M}_1(P)\]
and
\begin{equation}
\mathbf{c} = \mathbf{M}_3(P)\mathbf{v}(t). \label{eqn:b}
\end{equation}
Both $\mathbf{A}$ and $\mathbf{c}$ may be extracted from $\mathcal{R}$ easily.
Given the anti-symmetric and symmetric nature
of $\mathbf{M}_1(P)$ and $\mathbf{M}_2(P)$ it is clear that
\begin{align*}
\mathbf{A} + \mathbf{A}^T &= 
2\left[ c^2\mathbf{I}_3 - s^2\;\mathbf{M}_2(P) \right] \\
\mathbf{A} - \mathbf{A}^T &= 
4sc\;\mathbf{M}_1(P).
\end{align*}
If $sc \ne 0$ then we may recover $P$ by extracting elements of 
$\mathbf{A} - \mathbf{A}^{T}$ and renormalising. If $sc = 0$ then either
$s = 0$ or $c = 0$. If $s = 0$ it implies $\psi = 2n\pi$, $c = 1$ and 
therefore that 
$\mathbf{A} + \mathbf{A}^{T}$ should be the identity matrix and
we are free to choose $P$ as we wish. If $c = 0$ then $s = \pm 1$
and $\mathbf{A} + \mathbf{A}^{T} = 2 \mathbf{M}_2(P)$. We can then
extract $P$ from $\mathbf{M}_2(P)$. The sign of $s$, in this case, is arbitrary.

Assuming we have estimates for $s$, $k$ and $c$ from above, we may
estimate $\mathbf{M}_3(P)$ directly and hence recover
\[
\mathbf{v}(t) = \mathbf{M}^{-1}_3(P) \mathbf{c}.
\]
In practice we might wish to use LU decomposition or similar rather
than computing the matrix inverse if we deal with spaces with higer
dimensionality. Finally, given $s$, $c$ and $k$, an estimate for 
$\psi$ can be made. 
